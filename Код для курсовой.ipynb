{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>variant</th>\n",
       "      <th>group_id</th>\n",
       "      <th>chain_id</th>\n",
       "      <th>link</th>\n",
       "      <th>shift</th>\n",
       "      <th>length</th>\n",
       "      <th>content</th>\n",
       "      <th>tk_shifts</th>\n",
       "      <th>attributes</th>\n",
       "      <th>head</th>\n",
       "      <th>hd_shifts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>407840</td>\n",
       "      <td>1070</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>своих</td>\n",
       "      <td>9</td>\n",
       "      <td>ref:def|str:refl|type:coref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>407839</td>\n",
       "      <td>1070</td>\n",
       "      <td>407840</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>я</td>\n",
       "      <td>47</td>\n",
       "      <td>ref:def|str:pron|type:coref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>407842</td>\n",
       "      <td>1069</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>13</td>\n",
       "      <td>одинокую дачу</td>\n",
       "      <td>69,78</td>\n",
       "      <td>ref:def|str:noun|type:coref</td>\n",
       "      <td>дачу</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>407841</td>\n",
       "      <td>1069</td>\n",
       "      <td>407842</td>\n",
       "      <td>118</td>\n",
       "      <td>9</td>\n",
       "      <td>этой даче</td>\n",
       "      <td>118,123</td>\n",
       "      <td>ref:def|str:noun|type:coref</td>\n",
       "      <td>даче</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>407843</td>\n",
       "      <td>1069</td>\n",
       "      <td>407841</td>\n",
       "      <td>166</td>\n",
       "      <td>3</td>\n",
       "      <td>она</td>\n",
       "      <td>166</td>\n",
       "      <td>ref:def|str:pron|type:coref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  variant  group_id  chain_id    link  shift  length        content  \\\n",
       "0       1        1    407840      1070       0      9       5          своих   \n",
       "1       1        1    407839      1070  407840     47       1              я   \n",
       "2       1        1    407842      1069       0     69      13  одинокую дачу   \n",
       "3       1        1    407841      1069  407842    118       9      этой даче   \n",
       "4       1        1    407843      1069  407841    166       3            она   \n",
       "\n",
       "  tk_shifts                   attributes  head hd_shifts  \n",
       "0         9  ref:def|str:refl|type:coref   NaN       NaN  \n",
       "1        47  ref:def|str:pron|type:coref   NaN       NaN  \n",
       "2     69,78  ref:def|str:noun|type:coref  дачу        78  \n",
       "3   118,123  ref:def|str:noun|type:coref  даче       123  \n",
       "4       166  ref:def|str:pron|type:coref   NaN       NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = pd.read_table('groups.txt')\n",
    "groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groups = groups[groups.chain_id > 0].sort_values(by='chain_id') #отсортировали данные по chain_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groups.loc[:, 'first'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_ids = new_groups.groupby(\"chain_id\").aggregate(np.min)['shift'].get_values() # группируем по chain_id и выбираем минимум по shift\n",
    "\n",
    "for i in range(len(group_ids)):\n",
    "    new_groups.loc[new_groups[(new_groups['chain_id'] == i+1)&(new_groups['shift'] == group_ids[i])].index, 'first'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>variant</th>\n",
       "      <th>group_id</th>\n",
       "      <th>chain_id</th>\n",
       "      <th>link</th>\n",
       "      <th>shift</th>\n",
       "      <th>length</th>\n",
       "      <th>content</th>\n",
       "      <th>tk_shifts</th>\n",
       "      <th>attributes</th>\n",
       "      <th>head</th>\n",
       "      <th>hd_shifts</th>\n",
       "      <th>first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5903</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>413740</td>\n",
       "      <td>1</td>\n",
       "      <td>413739</td>\n",
       "      <td>3043</td>\n",
       "      <td>4</td>\n",
       "      <td>свои</td>\n",
       "      <td>3043</td>\n",
       "      <td>ref:def|str:refl|type:coref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5899</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>413736</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2835</td>\n",
       "      <td>15</td>\n",
       "      <td>многие дарители</td>\n",
       "      <td>2835,2842</td>\n",
       "      <td>ref:def|str:noun|type:coref</td>\n",
       "      <td>дарители</td>\n",
       "      <td>2842</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>413741</td>\n",
       "      <td>1</td>\n",
       "      <td>413740</td>\n",
       "      <td>3058</td>\n",
       "      <td>3</td>\n",
       "      <td>Они</td>\n",
       "      <td>3058</td>\n",
       "      <td>ref:def|str:pron|type:coref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5900</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>413737</td>\n",
       "      <td>1</td>\n",
       "      <td>413736</td>\n",
       "      <td>2861</td>\n",
       "      <td>4</td>\n",
       "      <td>свои</td>\n",
       "      <td>2861</td>\n",
       "      <td>ref:def|str:refl|type:coref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5901</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>413739</td>\n",
       "      <td>1</td>\n",
       "      <td>413737</td>\n",
       "      <td>2922</td>\n",
       "      <td>10</td>\n",
       "      <td>Эти страны</td>\n",
       "      <td>2922,2926</td>\n",
       "      <td>ref:def|str:noun|type:coref</td>\n",
       "      <td>страны</td>\n",
       "      <td>2926</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc_id  variant  group_id  chain_id    link  shift  length  \\\n",
       "5903      86        1    413740         1  413739   3043       4   \n",
       "5899      86        1    413736         1       0   2835      15   \n",
       "5904      86        1    413741         1  413740   3058       3   \n",
       "5900      86        1    413737         1  413736   2861       4   \n",
       "5901      86        1    413739         1  413737   2922      10   \n",
       "\n",
       "              content  tk_shifts                   attributes      head  \\\n",
       "5903             свои       3043  ref:def|str:refl|type:coref       NaN   \n",
       "5899  многие дарители  2835,2842  ref:def|str:noun|type:coref  дарители   \n",
       "5904              Они       3058  ref:def|str:pron|type:coref       NaN   \n",
       "5900             свои       2861  ref:def|str:refl|type:coref       NaN   \n",
       "5901       Эти страны  2922,2926  ref:def|str:noun|type:coref    страны   \n",
       "\n",
       "     hd_shifts  first  \n",
       "5903       NaN      0  \n",
       "5899      2842      1  \n",
       "5904       NaN      0  \n",
       "5900       NaN      0  \n",
       "5901      2926      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_groups.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получаем списки прилагательных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = new_groups[(new_groups['first'] == 1)&(new_groups['head'] != None)]['content'].to_string().split()\n",
    "A = [x.lower() for x in A if x.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = collections.Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in A:\n",
    "    p = morph.parse(word)[0]\n",
    "    if p.tag.POS == 'ADJF':\n",
    "        c[p.normal_form] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('свой', 69),\n",
       " ('этот', 46),\n",
       " ('один', 45),\n",
       " ('тот', 42),\n",
       " ('весь', 37),\n",
       " ('наш', 36),\n",
       " ('новый', 19),\n",
       " ('такой', 18),\n",
       " ('американский', 17),\n",
       " ('мой', 16),\n",
       " ('самый', 16),\n",
       " ('большой', 15),\n",
       " ('европейский', 15),\n",
       " ('ядерный', 15),\n",
       " ('главный', 14),\n",
       " ('российский', 13),\n",
       " ('некоторый', 12),\n",
       " ('русский', 12),\n",
       " ('международный', 11),\n",
       " ('другой', 11),\n",
       " ('каждый', 10),\n",
       " ('народный', 10),\n",
       " ('южный', 9),\n",
       " ('хороший', 9),\n",
       " ('небольшой', 9),\n",
       " ('западный', 8),\n",
       " ('футбольный', 8),\n",
       " ('оппозиционный', 8),\n",
       " ('немецкий', 8),\n",
       " ('какой', 8)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('first_adjectives.txt', 'w', encoding = 'utf-8')\n",
    "for item in list(c):\n",
    "    f.write(\"%s\\n\" % item)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = new_groups[(new_groups['first'] == 0)&(new_groups['head'] != None)]['content'].to_string().split()\n",
    "B = [x.lower() for x in B if x.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = collections.Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in B:\n",
    "    p = morph.parse(word)[0]\n",
    "    if p.tag.POS == 'ADJF':\n",
    "        d[p.normal_form] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('который', 737),\n",
       " ('свой', 543),\n",
       " ('этот', 220),\n",
       " ('мой', 126),\n",
       " ('наш', 112),\n",
       " ('тот', 66),\n",
       " ('сам', 56),\n",
       " ('её', 54),\n",
       " ('ядерный', 43),\n",
       " ('самый', 42),\n",
       " ('новый', 37),\n",
       " ('фри', 35),\n",
       " ('ваш', 32),\n",
       " ('весь', 28),\n",
       " ('один', 27),\n",
       " ('такой', 24),\n",
       " ('сундучанский', 21),\n",
       " ('большой', 21),\n",
       " ('российский', 20),\n",
       " ('южный', 15),\n",
       " ('бывший', 13),\n",
       " ('старый', 11),\n",
       " ('обыкновенный', 11),\n",
       " ('летний', 10),\n",
       " ('английский', 10),\n",
       " ('американский', 9),\n",
       " ('высокий', 9),\n",
       " ('народный', 9),\n",
       " ('общий', 9),\n",
       " ('главный', 9)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = c - d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('один', 18),\n",
       " ('некоторый', 12),\n",
       " ('каждый', 9),\n",
       " ('весь', 9),\n",
       " ('американский', 8),\n",
       " ('европейский', 7),\n",
       " ('другой', 7),\n",
       " ('немецкий', 7),\n",
       " ('собственный', 6),\n",
       " ('местный', 6),\n",
       " ('оппозиционный', 6),\n",
       " ('русский', 6),\n",
       " ('мелкий', 6),\n",
       " ('общественный', 6),\n",
       " ('радикальный', 5),\n",
       " ('западный', 5),\n",
       " ('национальный', 5),\n",
       " ('хороший', 5),\n",
       " ('небольшой', 5),\n",
       " ('главный', 5),\n",
       " ('какой', 5),\n",
       " ('огромный', 5),\n",
       " ('глобальный', 5),\n",
       " ('окружающий', 5),\n",
       " ('многий', 5),\n",
       " ('радиоактивный', 5),\n",
       " ('московский', 5),\n",
       " ('наивный', 5),\n",
       " ('социальный', 4),\n",
       " ('широкий', 4)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_first_adjectives = []\n",
    "for i in range (61):\n",
    "    common_first_adjectives.append(c1.most_common(61)[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('not_first_adjectives.txt', 'w', encoding = 'utf-8')\n",
    "for item in list(d):\n",
    "    f.write(\"%s\\n\" % item)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Подготовка к baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = pd.read_table('Documents.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Признак \"совпадение именной группы\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groups['content coincidence'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(181): # идём по документам\n",
    "    f = open('rucoref_texts/'+ documents['path'][i], 'r', encoding = 'utf-8' )\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "    indexes = new_groups[new_groups['doc_id'] == documents['doc_id'][i]]['content'].index \n",
    "    for index in indexes: # идём по content'ам\n",
    "        if text.find(new_groups['content'][index]) == new_groups['shift'][index]: #находим первое упоминание content в тексте и сверяем с настоящим местом content (shift) \n",
    "            new_groups.loc[index, 'content coincidence'] = 1 # если первое упоминание совпало с шифтом, то признак 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Признак \"совпадение вершины\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groups['head coincidence'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(181):\n",
    "    f = open('rucoref_texts/'+ documents['path'][i], 'r', encoding = 'utf-8')\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "    indexes = new_groups[new_groups['doc_id'] == documents['doc_id'][i]]['head'].index\n",
    "    for index in indexes:\n",
    "        if str(text.find(str(new_groups['head'][index]))) == new_groups['hd_shifts'][index]:\n",
    "            new_groups.loc[index, 'head coincidence'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Признак \"является ли местоимением\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groups['is_pron'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = new_groups['content'].index \n",
    "for index in indexes: # идём по contentам\n",
    "    p = morph.parse(new_groups['content'][index])[0]\n",
    "    if p.tag.POS != 'NOUN': #если ИГ -  не существительное,  \n",
    "        new_groups.loc[index, 'is_pron'] = 0 # то признак = 0 (тогда вероятно, что это НЕ первое упоминание)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Признак \"количество прилагательных\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groups['number_of_adj'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = new_groups['content'].index \n",
    "for index in indexes: # идём по contentам\n",
    "    words = new_groups['content'][index].split()\n",
    "    num_adj = 0 #счетчик прилагательных\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        if p.tag.POS == 'ADJF': #если ИГ -  прилагательное,\n",
    "            num_adj += 1 #прибавляем 1\n",
    "    if num_adj >= 1: #если прилагательных больше одного\n",
    "        new_groups.loc[index, 'number_of_adj'] = 1 # то признак = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_groups[['content coincidence','head coincidence', 'is_pron', 'number_of_adj']]\n",
    "Y = new_groups['first']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая Регресссия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.80      0.95      0.87      3828\n",
      "     class 1       0.58      0.21      0.31      1122\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      4950\n",
      "   macro avg       0.69      0.58      0.59      4950\n",
      "weighted avg       0.75      0.79      0.75      4950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "lin_svm = SVC(kernel='linear', C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = lin_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.82      0.94      0.88      3828\n",
      "     class 1       0.59      0.28      0.38      1122\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      4950\n",
      "   macro avg       0.71      0.61      0.63      4950\n",
      "weighted avg       0.77      0.79      0.76      4950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.82      0.93      0.87      3828\n",
      "     class 1       0.55      0.31      0.40      1122\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      4950\n",
      "   macro avg       0.69      0.62      0.63      4950\n",
      "weighted avg       0.76      0.79      0.76      4950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred3, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Эксперименты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Длина"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groups['len'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.011031640198812"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_groups.length.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groups.loc[new_groups.length >= 10, 'len'] = 1 #4911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = new_groups[['content coincidence','head coincidence', 'is_pron', 'number_of_adj', 'len']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X1, Y, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.84      0.88      0.86      3828\n",
      "     class 1       0.52      0.45      0.48      1122\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      4950\n",
      "   macro avg       0.68      0.66      0.67      4950\n",
      "weighted avg       0.77      0.78      0.77      4950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.83      0.90      0.86      3828\n",
      "     class 1       0.52      0.37      0.43      1122\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      4950\n",
      "   macro avg       0.68      0.64      0.65      4950\n",
      "weighted avg       0.76      0.78      0.77      4950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.82      0.94      0.88      3828\n",
      "     class 1       0.59      0.28      0.38      1122\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      4950\n",
      "   macro avg       0.71      0.61      0.63      4950\n",
      "weighted avg       0.77      0.79      0.76      4950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lin_svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Второй эксперимент с длиной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groups['len1'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.8485931913570655"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_groups[new_groups['first'] == 0].length.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groups.loc[new_groups.length >= 8, 'len1'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = new_groups[['content coincidence','head coincidence', 'is_pron', 'number_of_adj', 'len1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X1, Y, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.85      0.84      0.85      3828\n",
      "     class 1       0.48      0.50      0.49      1122\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      4950\n",
      "   macro avg       0.67      0.67      0.67      4950\n",
      "weighted avg       0.77      0.77      0.77      4950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.80      0.96      0.87      3828\n",
      "     class 1       0.58      0.21      0.31      1122\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      4950\n",
      "   macro avg       0.69      0.58      0.59      4950\n",
      "weighted avg       0.75      0.79      0.75      4950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.82      0.94      0.88      3828\n",
      "     class 1       0.59      0.28      0.38      1122\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      4950\n",
      "   macro avg       0.71      0.61      0.63      4950\n",
      "weighted avg       0.77      0.79      0.76      4950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lin_svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы по экспериментам с длиной:\n",
    "    \n",
    "    Для knn эффективнее использовать среднее значение повторных ИГ (видимо, из-за того, что в результате к первому классу будет относиться больше ИГ)\n",
    "    \n",
    "    Для логистической регрессии эффективнее использовать среднее значение по всем ИГ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прилагательные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groups['is_adj'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indexes = new_groups['content'].index \n",
    "for index in indexes: # идём по contentам\n",
    "    words = new_groups['content'][index].split()\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        if p.tag.POS == 'ADJF': #если ИГ -  прилагательное,\n",
    "            if p.normal_form in common_first_adjectives:\n",
    "                new_groups.loc[index, 'is_adj'] = 1 # то признак = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X2 = new_groups[['content coincidence','head coincidence', 'is_pron', 'len1', 'is_adj']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X2, Y, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.84      0.83      0.84      3828\n",
      "     class 1       0.45      0.47      0.46      1122\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      4950\n",
      "   macro avg       0.64      0.65      0.65      4950\n",
      "weighted avg       0.75      0.75      0.75      4950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = new_groups[['content coincidence','head coincidence', 'is_pron', 'len', 'is_adj']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X2, Y, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.82      0.95      0.88      3828\n",
      "     class 1       0.61      0.26      0.37      1122\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      4950\n",
      "   macro avg       0.71      0.61      0.62      4950\n",
      "weighted avg       0.77      0.80      0.76      4950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = lr_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.83      0.94      0.88      3828\n",
      "     class 1       0.61      0.33      0.43      1122\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      4950\n",
      "   macro avg       0.72      0.64      0.66      4950\n",
      "weighted avg       0.78      0.80      0.78      4950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = lin_svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred2, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
